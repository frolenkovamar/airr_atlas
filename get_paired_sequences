{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPhXzS8+d4yuI8jC3mXurrP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6EhiU-H5wDbh","executionInfo":{"status":"ok","timestamp":1697185052519,"user_tz":-480,"elapsed":21962,"user":{"displayName":"Marina Frolenkova","userId":"17659962542562539736"}},"outputId":"b015765a-fae5-4790-f0ef-903c76a3abb4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["!ls drive/MyDrive/Oslo/data/Annotations"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tGMBZ5ZYwki4","executionInfo":{"status":"ok","timestamp":1696172642539,"user_tz":-480,"elapsed":302,"user":{"displayName":"Marina Frolenkova","userId":"17659962542562539736"}},"outputId":"f45f82d3-aa53-45de-df76-83acdebb86fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cdr3_specificity.anno\t      combined_distinct_light.anno\n","combined_distinct_heavy.anno  specificity.anno\n"]}]},{"cell_type":"markdown","source":["# **Paired CDR3 sequences**"],"metadata":{"id":"c9E4MzvHw6NC"}},{"cell_type":"code","source":["annotation_path = 'drive/MyDrive/Oslo/data/Annotations/cdr3_specificity.anno'\n","light_chain_path = 'drive/MyDrive/Oslo/data/FASTA/combined_cdr3_light.fa'\n","heavy_chain_path = 'drive/MyDrive/Oslo/data/FASTA/combined_cdr3_heavy.fa'"],"metadata":{"id":"B4CKsOzfxEps"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read the pairs of IDs from the annotation file\n","pairs = []\n","with open(f'{annotation_path}', 'r') as file:\n","    next(file)  # Skip the header line\n","    for line in file:\n","        columns = line.strip().split('\\t')\n","        heavy_id = columns[0]\n","        light_id = columns[1]\n","        pairs.append((heavy_id, light_id))\n","\n","# Read the light and heavy chain files into dictionaries\n","light_chains = {}\n","with open(f'{light_chain_path}', 'r') as file:\n","    lines = file.readlines()\n","    for i in range(0, len(lines), 2):\n","        light_id = lines[i].strip().strip('>')\n","        light_seq = lines[i+1].strip()\n","        light_chains[light_id] = light_seq\n","\n","heavy_chains = {}\n","with open(f'{heavy_chain_path}', 'r') as file:\n","    lines = file.readlines()\n","    for i in range(0, len(lines), 2):\n","        heavy_id = lines[i].strip().strip('>')\n","        heavy_seq = lines[i+1].strip()\n","        heavy_chains[heavy_id] = heavy_seq\n","\n","# Create a set to track merged chains and a list to maintain order\n","merged_chain_set = set()\n","merged_chains_list = []\n","\n","# Iterate through the pairs and merge chains, eliminating duplicates\n","for heavy_id, light_id in pairs:\n","    if heavy_id in heavy_chains and light_id in light_chains:\n","        merged_chain = heavy_chains[heavy_id] + light_chains[light_id]\n","        if merged_chain not in merged_chain_set:\n","            merged_chain_set.add(merged_chain)\n","            merged_chains_list.append((heavy_id, light_id, merged_chain))\n","\n","# Create a new file with merged chains without duplicates\n","with open('paired_cdr3.fa', 'w') as output_file:\n","    for heavy_id, light_id, merged_chain in merged_chains_list:\n","        output_file.write(f\">{heavy_id}_{light_id}\\n{merged_chain}\\n\")"],"metadata":{"id":"Cm3sddw8wzv7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wc -l paired_cdr3.fa"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vY0qfTC_8J8Q","executionInfo":{"status":"ok","timestamp":1696175699609,"user_tz":-480,"elapsed":335,"user":{"displayName":"Marina Frolenkova","userId":"17659962542562539736"}},"outputId":"6a434357-adb8-4da0-b560-efd93d6cfba0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["133430 paired_cdr3.fa\n"]}]},{"cell_type":"markdown","source":["# **Full-length CDR3 sequences**"],"metadata":{"id":"jM9N2T9A33vn"}},{"cell_type":"code","source":["annotation_path = 'drive/MyDrive/Oslo/data/Annotations/specificity.anno'\n","light_chain_path = 'drive/MyDrive/Oslo/data/FASTA/combined_distinct_light.fa'\n","heavy_chain_path = 'drive/MyDrive/Oslo/data/FASTA/combined_distinct_heavy.fa'"],"metadata":{"id":"3gVH0HSc3-Zw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read the pairs of IDs from the annotation file\n","pairs = []\n","with open(f'{annotation_path}', 'r') as file:\n","    next(file)  # Skip the header line\n","    for line in file:\n","        columns = line.strip().split('\\t')\n","        heavy_id = columns[0]\n","        light_id = columns[1]\n","        pairs.append((heavy_id, light_id))\n","\n","# Read the light and heavy chain files into dictionaries\n","light_chains = {}\n","with open(f'{light_chain_path}', 'r') as file:\n","    lines = file.readlines()\n","    for i in range(0, len(lines), 2):\n","        light_id = lines[i].strip().strip('>')\n","        light_seq = lines[i+1].strip()\n","        light_chains[light_id] = light_seq\n","\n","heavy_chains = {}\n","with open(f'{heavy_chain_path}', 'r') as file:\n","    lines = file.readlines()\n","    for i in range(0, len(lines), 2):\n","        heavy_id = lines[i].strip().strip('>')\n","        heavy_seq = lines[i+1].strip()\n","        heavy_chains[heavy_id] = heavy_seq\n","\n","# Create a set to track merged chains and a list to maintain order\n","merged_chain_set = set()\n","merged_chains_list = []\n","\n","# Iterate through the pairs and merge chains, eliminating duplicates\n","for heavy_id, light_id in pairs:\n","    if heavy_id in heavy_chains and light_id in light_chains:\n","        merged_chain = heavy_chains[heavy_id] + light_chains[light_id]\n","        if merged_chain not in merged_chain_set:\n","            merged_chain_set.add(merged_chain)\n","            merged_chains_list.append((heavy_id, light_id, merged_chain))\n","\n","# Create a new file with merged chains without duplicates\n","with open('paired_full.fa', 'w') as output_file:\n","    for heavy_id, light_id, merged_chain in merged_chains_list:\n","        output_file.write(f\">{heavy_id}_{light_id}\\n{merged_chain}\\n\")"],"metadata":{"id":"uH3iqTGi4D-c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wc -l paired_full.fa"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-yBTgLuJ8dhk","executionInfo":{"status":"ok","timestamp":1696175696209,"user_tz":-480,"elapsed":315,"user":{"displayName":"Marina Frolenkova","userId":"17659962542562539736"}},"outputId":"9dd86812-89c0-407c-9c65-b57a5a03d7a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["135300 paired_full.fa\n"]}]},{"cell_type":"markdown","source":["# **Get OLGA-formatted CDR3s**"],"metadata":{"id":"QeMAIkMfHFep"}},{"cell_type":"code","source":["!ls drive/MyDrive/Oslo/data/FASTA"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yLcnC8NKHNl_","executionInfo":{"status":"ok","timestamp":1697185069012,"user_tz":-480,"elapsed":8,"user":{"displayName":"Marina Frolenkova","userId":"17659962542562539736"}},"outputId":"d016d9c3-3f5c-4917-ebdb-6787d5691d9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["combined_cdr3_heavy.csv      combined_distinct_heavy.fa\n","combined_cdr3_heavy.fa\t     combined_distinct_light.csv\n","combined_cdr3_light.csv      combined_distinct_light.fa\n","combined_cdr3_light.fa\t     paired_full_length.fa\n","combined_distinct_heavy.csv\n"]}]},{"cell_type":"code","source":["chain = 'H'\n","\n","# Function to read a FASTA file and return a dictionary of sequences\n","def read_fasta(file_path):\n","    sequences = {}\n","    with open(file_path, 'r') as file:\n","        current_id = None\n","        current_sequence = ''\n","        for line in file:\n","            line = line.strip()\n","            if line.startswith('>'):\n","                if current_id is not None:\n","                    sequences[current_id] = current_sequence\n","                current_id = line[1:]\n","                current_sequence = ''\n","            else:\n","                current_sequence += line\n","        if current_id is not None:\n","            sequences[current_id] = current_sequence\n","    return sequences\n","\n","# Input file paths\n","if chain == 'H':\n","    full_length_file = 'drive/MyDrive/Oslo/data/FASTA/combined_distinct_heavy.fa'\n","    cdr3_file = 'drive/MyDrive/Oslo/data/FASTA/combined_cdr3_heavy.fa'\n","    output_file = 'olga_cdr3_heavy.fa'\n","else:\n","    full_length_file = 'drive/MyDrive/Oslo/data/FASTA/combined_distinct_light.fa'\n","    cdr3_file = 'drive/MyDrive/Oslo/data/FASTA/combined_cdr3_light.fa'\n","    output_file = 'olga_cdr3_light.fa'\n","\n","# Read the sequences from the two input FASTA files\n","full_length_sequences = read_fasta(full_length_file)\n","cdr3_sequences = read_fasta(cdr3_file)\n","\n","# Create a new FASTA file with CDR3 sequences and two additional letters\n","with open(output_file, 'w') as outfile:\n","    for cdr3_id, cdr3_sequence in cdr3_sequences.items():\n","        if cdr3_id in full_length_sequences:\n","            full_length_sequence = full_length_sequences[cdr3_id]\n","            start = full_length_sequence.find(cdr3_sequence)\n","            if start != -1:\n","                extended_cdr3 = full_length_sequence[start - 1:start + len(cdr3_sequence) + 1]\n","\n","                #print(cdr3_sequence)\n","                #print(extended_cdr3)\n","                #print()\n","\n","                outfile.write(f'>{cdr3_id}\\n{extended_cdr3}\\n')\n","            else:\n","              print(f'{cdr3_sequence} not found in {cdr3_id}')"],"metadata":{"id":"5BEjaQfebZ9P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chain = 'H'\n","\n","# Function to read a FASTA file and return a dictionary of sequences\n","def read_fasta(file_path):\n","    sequences = {}\n","    with open(file_path, 'r') as file:\n","        current_id = None\n","        current_sequence = ''\n","        for line in file:\n","            line = line.strip()\n","            if line.startswith('>'):\n","                if current_id is not None:\n","                    sequences[current_id] = current_sequence\n","                current_id = line[1:]\n","                current_sequence = ''\n","            else:\n","                current_sequence += line\n","        if current_id is not None:\n","            sequences[current_id] = current_sequence\n","    return sequences\n","\n","# Input file paths\n","if chain == 'H':\n","    full_length_file = 'drive/MyDrive/Oslo/data/FASTA/combined_distinct_heavy.fa'\n","    cdr3_file = 'drive/MyDrive/Oslo/data/FASTA/combined_cdr3_heavy.fa'\n","    output_file = 'olga_cdr3_heavy.fa'\n","else:\n","    full_length_file = 'drive/MyDrive/Oslo/data/FASTA/combined_distinct_light.fa'\n","    cdr3_file = 'drive/MyDrive/Oslo/data/FASTA/combined_cdr3_light.fa'\n","    output_file = 'olga_cdr3_light.fa'\n","\n","# Read the sequences from the two input FASTA files\n","full_length_sequences = read_fasta(full_length_file)\n","cdr3_sequences = read_fasta(cdr3_file)\n","\n","# Create a new FASTA file with CDR3 sequences and two additional letters\n","with open(output_file, 'w') as outfile:\n","    for cdr3_id, cdr3_sequence in cdr3_sequences.items():\n","        # Search for CDR3 sequence in full-length sequences\n","        found = False\n","        for full_id, full_sequence in full_length_sequences.items():\n","            if cdr3_sequence in full_sequence:\n","                start = full_sequence.find(cdr3_sequence)\n","                extended_cdr3 = full_sequence[start - 1:start + len(cdr3_sequence) + 1]\n","                outfile.write(f'>{cdr3_id}\\n{extended_cdr3}\\n')\n","                found = True\n","                break\n","\n","        if not found:\n","            print(f'{cdr3_sequence} not found in any full-length sequence')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TXHB60HSS-35","outputId":"c48bc3b9-a055-4135-99d6-a51712ec75cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ATDYSNYISAGRYYFYYME not found in any full-length sequence\n","ARHVDVTMYSAFDF not found in any full-length sequence\n"]}]}]}